<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Note on 赵大宝的博客</title>
    <link>https://dabao-zhao.github.io/categories/note/</link>
    <description>Recent content in Note on 赵大宝的博客</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Tue, 15 Aug 2023 09:51:35 +0800</lastBuildDate><atom:link href="https://dabao-zhao.github.io/categories/note/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>稀疏索引：为什么高并发写不推荐关系数据库</title>
      <link>https://dabao-zhao.github.io/posts/%E7%A8%80%E7%96%8F%E7%B4%A2%E5%BC%95%E4%B8%BA%E4%BB%80%E4%B9%88%E9%AB%98%E5%B9%B6%E5%8F%91%E5%86%99%E4%B8%8D%E6%8E%A8%E8%8D%90%E5%85%B3%E7%B3%BB%E6%95%B0%E6%8D%AE%E5%BA%93/</link>
      <pubDate>Tue, 15 Aug 2023 09:51:35 +0800</pubDate>
      
      <guid>https://dabao-zhao.github.io/posts/%E7%A8%80%E7%96%8F%E7%B4%A2%E5%BC%95%E4%B8%BA%E4%BB%80%E4%B9%88%E9%AB%98%E5%B9%B6%E5%8F%91%E5%86%99%E4%B8%8D%E6%8E%A8%E8%8D%90%E5%85%B3%E7%B3%BB%E6%95%B0%E6%8D%AE%E5%BA%93/</guid>
      <description>B+Tree MySQL 几乎所有查询都是通过索引去缩小扫描数据的范围，然后再回到表中对范围内数据进行遍历加工、过滤，最终拿到我们的业务需要的数据。
B+Tree 的特点在于只有在最底层才会存储真正的数据 ID，通过这个 ID 就可以提取到数据的具体内容，同时 B+Tree 索引最底层的数据是按索引字段顺序进行存储的。 通过这种设计方式，我们只需进行 1～3 次 IO（树深度决定了 IO 次数）就能找到所查范围内序好的数据，而树形的索引最影响查询效率的是树的深度以及数据量。
MySQL 的索引是使用 Page 作为单位进行存储的，而每页只能存储 16KB（innodb_page_size）数据。如果我们每行数据的索引是1KB，那么除去 Page 页的一些固定 结构占用外，一页只能放 16 条数据，这导致树的一些分支装不下更多数据时，就需要对索引的深度再加一层。就可以推导出：索引第一层放 16 条，树第二层大概能放 2 万条， 树第三层大概能放 2400 万条，三层的深度 B+Tree 按主键查找数据每次查询需要 3 次 IO（一层索引在内存，IO 两次索引，最后一次是拿数据），这也是一些文章会推荐说 MySQL 的单表记录最好不要超过 2000 万条的原因。
不过不是绝对的，和每行数据的大小有关系
B+Tree 其实有些离题了……但是硬说也能原回来，因为索引太多也是会影响写入速度的
文中最后总结不适合的原因是：主从的部署模式，大批量的插入会造成主库响应缓慢、主从同步延迟增大等问题
稀疏索引 LSM Tree TODO 后面再找个教程
主要以 RocksDB 为例介绍。
RocksDB LSM 新数据写入时会在内存中暂存，当内存中数据积累到一定程度后，会将内存中数据和索引做顺序写，落地形成一个数据块。新生成的数据块会保存在 Level 0 层， 每一层的数据块和数据量超过一定程度时，RocksDB 合并不同 Level 的数据，将多个数据块内的数据和索引合并在一起，并推送到 Level 的下一层。
当我们查询一个 key 的时候，RocksDB 会先查内存。如果没找到，会从 Level 0 层到下层，每层按生成最新到最老的顺序去查询每层的数据块。同时为了减少 IO 次数，每个数据块 都会有一个 BloomFilter 辅助索引，来辅助确认这个数据块中是否可能有对应的 Key；如果当前数据块没有，那么可以快速去找下一个数据块，直到找到为止。</description>
    </item>
    
    <item>
      <title>分布式事务：多服务的2PC、TCC都是怎么实现的</title>
      <link>https://dabao-zhao.github.io/posts/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E5%A4%9A%E6%9C%8D%E5%8A%A1%E7%9A%842pctcc%E9%83%BD%E6%98%AF%E6%80%8E%E4%B9%88%E5%AE%9E%E7%8E%B0%E7%9A%84/</link>
      <pubDate>Mon, 14 Aug 2023 14:51:34 +0800</pubDate>
      
      <guid>https://dabao-zhao.github.io/posts/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E5%A4%9A%E6%9C%8D%E5%8A%A1%E7%9A%842pctcc%E9%83%BD%E6%98%AF%E6%80%8E%E4%B9%88%E5%AE%9E%E7%8E%B0%E7%9A%84/</guid>
      <description>XA 协议 三个角色 应用（AP） 应用是具体的业务逻辑代码实现，业务逻辑通过请求事务协调器开启全局事务，在事务协调器注册多个子事务后，业务代码会依次给所有参与事务的子业务下发请求。 待所有子业务提交成功后，业务代码根据返回情况告诉事务协调器各个子事务的执行情况，由事务协调器决策子事务是提交还是回滚（有些实现是事务协调器发请求给子服务）。
事务协调器（TM） 用于创建主事务，同时协调各个子事务。事务协调器会根据各个子事务的执行情况，决策这些子事务最终是提交执行结果，还是回滚执行结果。此外，事务协调器很多时候还会自动帮我们提交事务；
资源管理器（RM） 是一种支持事务或 XA 协议的数据资源，比如 MySQL、Redis 等
两个阶段 Prepare 阶段 在 Prepare 阶段，事务协调器会通过 xid（事务唯一标识，由业务或事务协调器生成）协调多个资源管理器执行子事务，所有子事务执行成功后会向事务协调器汇报。 这时的子事务执行成功是指事务内 SQL 执行成功，并没有执行事务的最终 commit（提交），所有子事务是提交还是回滚，需要等事务协调器做最终决策。
Commit 阶段 当事务协调器收到所有资源管理器成功执行子事务的消息后，会记录事务执行成功，并对子事务做真正提交。如果 Prepare 阶段有子事务失败，或者事务协调器在一段 时间内没有收到所有子事务执行成功的消息，就会通知所有资源管理器对子事务执行回滚的操作。
事务的几个状态 ACTIVE：子事务 SQL 正在执行中； IDLE：子事务执行完毕等待切换 Prepared 状态，如果本次操作不参与回滚，就可以直接提交完成； PREPARED：子事务执行完毕，等待其他服务实例的子事务全部 Ready。 COMMITED/FAILED：所有子事务执行成功 / 失败后，一起提交或回滚。 2PC 缺点：
同步阻塞问题：事务的执行过程中，所有参与事务的节点都会对其占用的公共资源加锁，导致其他访问公共资源的进程或者线程阻塞。 单点故障问题：如果事务管理器发生故障，则资源管理器会一直阻塞。 数据不一致问题：如果在 Commit 阶段，由于网络或者部分资源管理器发生故障，导致部分资源管理器没有接收到事务管理器发送过来的 Commit 消息，会引起数据不一致的问题。 无法解决的问题：如果在 Commit 阶段，事务管理器发出 Commit 消息后宕机，并且唯一接收到这条 Commit 消息的资源管理器也宕机了，则无法确认事务是否已经提交。 3PC 3PC 模型把 2PC 模型中的 Prepare 阶段一分为二，最终形成 3 个阶段：
CanCommit 阶段：为了减少因等待锁定数据导致的超时情况，提高事务成功率，事务协调器会发送消息确认资源管理器的资源锁定情况，以及所有子事务的数据库锁定数据的情况。 PreCommit 阶段：执行 2PC 的 Prepare 阶段； DoCommit 阶段：执行 2PC 的 Commit 阶段。 缺点：</description>
    </item>
    
    <item>
      <title>系统隔离：如何应对高并发流量冲击</title>
      <link>https://dabao-zhao.github.io/posts/%E7%B3%BB%E7%BB%9F%E9%9A%94%E7%A6%BB%E5%A6%82%E4%BD%95%E5%BA%94%E5%AF%B9%E9%AB%98%E5%B9%B6%E5%8F%91%E6%B5%81%E9%87%8F%E5%86%B2%E5%87%BB/</link>
      <pubDate>Mon, 14 Aug 2023 14:07:19 +0800</pubDate>
      
      <guid>https://dabao-zhao.github.io/posts/%E7%B3%BB%E7%BB%9F%E9%9A%94%E7%A6%BB%E5%A6%82%E4%BD%95%E5%BA%94%E5%AF%B9%E9%AB%98%E5%B9%B6%E5%8F%91%E6%B5%81%E9%87%8F%E5%86%B2%E5%87%BB/</guid>
      <description>感觉又是水的一篇
首先是部署的隔离，内网和外网部署要物理隔离 然后是网关的隔离，内网网关和外网网关隔离，流量经过外网网关、外网、内网网关才能到内网。其中外网网关和内网网关都可以做限流和熔断。外网服务要保证内网 网关断开后，仍旧能正常独立运转一小时以上。 然后是减少外网和内网的 api 互动，内外通过缓存来交互数据，但要保证数据同步是单向的。如果内网想要修改数据可以通过请求外网接口，外网对内网的数据同步可以通过消息队列。 然后是讲了消息队列的优点：
队列拥有良好吞吐并且能够动态扩容，可应对各种流量冲击场景； 可通过动态控制内网消费线程数，从而实现内网流量可控； 内网消费服务在高峰期可以暂时离线，内网服务可以临时做一些停机升级操作； 内网服务如果出现 bug，导致消费数据丢失，可以对队列消息进行回放实现重新消费； Kafka 是分区消息同步，消息是顺序的，很少会乱序，可以帮我们实现顺序同步； 消息内容可以保存很久，加入 TraceID 后查找方便并且透明，利于排查各种问题。 感觉水的一部分原因是太理论了，和实战没啥关系……</description>
    </item>
    
    <item>
      <title>强一致锁：如何解决高并发下的库存争抢问题</title>
      <link>https://dabao-zhao.github.io/posts/%E5%BC%BA%E4%B8%80%E8%87%B4%E9%94%81%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3%E9%AB%98%E5%B9%B6%E5%8F%91%E4%B8%8B%E7%9A%84%E5%BA%93%E5%AD%98%E4%BA%89%E6%8A%A2%E9%97%AE%E9%A2%98/</link>
      <pubDate>Mon, 14 Aug 2023 11:11:17 +0800</pubDate>
      
      <guid>https://dabao-zhao.github.io/posts/%E5%BC%BA%E4%B8%80%E8%87%B4%E9%94%81%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3%E9%AB%98%E5%B9%B6%E5%8F%91%E4%B8%8B%E7%9A%84%E5%BA%93%E5%AD%98%E4%BA%89%E6%8A%A2%E9%97%AE%E9%A2%98/</guid>
      <description></description>
    </item>
    
    <item>
      <title>领域拆分：如何合理地拆分系统</title>
      <link>https://dabao-zhao.github.io/posts/%E9%A2%86%E5%9F%9F%E6%8B%86%E5%88%86%E5%A6%82%E4%BD%95%E5%90%88%E7%90%86%E5%9C%B0%E6%8B%86%E5%88%86%E7%B3%BB%E7%BB%9F/</link>
      <pubDate>Thu, 10 Aug 2023 17:10:18 +0800</pubDate>
      
      <guid>https://dabao-zhao.github.io/posts/%E9%A2%86%E5%9F%9F%E6%8B%86%E5%88%86%E5%A6%82%E4%BD%95%E5%90%88%E7%90%86%E5%9C%B0%E6%8B%86%E5%88%86%E7%B3%BB%E7%BB%9F/</guid>
      <description>以供货协商流程为例讲述了如何拆分系统。
首先进行流程分析，要多和产品、研发团队沟通，以确定主要流程的数据走向和系统数据的依赖关系没有问题。 然后以一个数据实体不能承载太多职能为原则，将承担太多职能的部分进行拆分。 然后再分析系统的核心是否和当前系统实现的一致，如果不一致需要对模块进行拆分。 然后根据角色和流程梳理后的结果，按角色和其所需要的动作整理出新的流程图。 总体来讲，主要是根据流程、角色和关键元素做为切入点，然后将不同流程划分出不同阶段来归类分析，根据不同阶段拆分出不同的模块，然后再和产品和研发论证可行性。
上面主要讲了大体上应该怎么拆，下面主要讲细节上该怎么入手。
一般来说，系统功能从表拆分比较容易，因为业务流程基本都会围绕实体表运转，并关联多个实体进行交互。主要的拆分依据是：
数据实体职能只做最核心的一件事 业务流程归类按涉及实体进行归类，看能否分为多个阶段 由数据依赖交叉的频率决定是否把模块拆分，如果交互频繁可以合并 然后就是抽象的处理，越是底层的服务，越要注意抽象，主要为了减少变更，避免影响其他服务，因为很难确认底层的变更对上游系统的影响范围。
几个常见的抽象思路：
被动抽象法 如果两个或多个服务使用同一个业务逻辑，就把这个业务逻辑抽象成公共服务。适合代码量不大、维护人员很少、处于探索阶段的系统。
同层级之间的模块是禁止相互调用的。如果调用了，就需要将两个服务抽象成公共服务，让上层对两个服务进行聚合，目的是为了让系统结构从上到下是一个倒置的树形， 保证不会出现引用交叉循环的情况
动态辅助表 适用于规模稍微大一点的团队或系统。
如果一个表被多个开发组使用，而不同的业务特性也不同，可以在主表内存储 type，然后再根据 type 去对应不同的辅助表。例如：普通商品保存在表 order 和表 order_product_extra 中，定制类商品保存在 order_customize_extra 中。
强制标准接口 底层服务只做标准的服务，业务的个性部分都由业务自己完成。算是比较常见的做法。
总结 先从上到下做业务流程梳理，将流程归类聚合；然后从不同的领域聚合中找出交互所需主要实体，根据流程中主要实体之间的数据依赖程度决定是否拆分（从下到上看）； 把不同的实体和动作拆分成多个模块后，再根据业务流程归类，划分出最终的模块（最终汇总）。
极客时间的课，总结往往特别精华……</description>
    </item>
    
    <item>
      <title>共识Raft：如何保证多机房数据的一致性</title>
      <link>https://dabao-zhao.github.io/posts/%E5%85%B1%E8%AF%86raft%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E5%A4%9A%E6%9C%BA%E6%88%BF%E6%95%B0%E6%8D%AE%E7%9A%84%E4%B8%80%E8%87%B4%E6%80%A7/</link>
      <pubDate>Wed, 09 Aug 2023 11:20:37 +0800</pubDate>
      
      <guid>https://dabao-zhao.github.io/posts/%E5%85%B1%E8%AF%86raft%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E5%A4%9A%E6%9C%BA%E6%88%BF%E6%95%B0%E6%8D%AE%E7%9A%84%E4%B8%80%E8%87%B4%E6%80%A7/</guid>
      <description>答：基于 Raft 协议的分布式数据服务
参考资料 raft 算法的动画展示 官网 中文论文 </description>
    </item>
    
    <item>
      <title>同城双活：如何实现机房之间的数据同步</title>
      <link>https://dabao-zhao.github.io/posts/%E5%90%8C%E5%9F%8E%E5%8F%8C%E6%B4%BB%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E6%9C%BA%E6%88%BF%E4%B9%8B%E9%97%B4%E7%9A%84%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5/</link>
      <pubDate>Wed, 09 Aug 2023 10:58:10 +0800</pubDate>
      
      <guid>https://dabao-zhao.github.io/posts/%E5%90%8C%E5%9F%8E%E5%8F%8C%E6%B4%BB%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E6%9C%BA%E6%88%BF%E4%B9%8B%E9%97%B4%E7%9A%84%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5/</guid>
      <description>答：otter
TODO 后面再找一个 otter 的教程吧
常见的网络延迟参考 指一次 RTT 请求
同机房服务器：0.1 ms 同城服务器（100 公里以内）：1ms 北京到上海：38ms 北京到广州：53ms </description>
    </item>
    
    <item>
      <title>Token：如何降低用户身份鉴权的流量压力？</title>
      <link>https://dabao-zhao.github.io/posts/token%E5%A6%82%E4%BD%95%E9%99%8D%E4%BD%8E%E7%94%A8%E6%88%B7%E8%BA%AB%E4%BB%BD%E9%89%B4%E6%9D%83%E7%9A%84%E6%B5%81%E9%87%8F%E5%8E%8B%E5%8A%9B/</link>
      <pubDate>Tue, 08 Aug 2023 17:21:24 +0800</pubDate>
      
      <guid>https://dabao-zhao.github.io/posts/token%E5%A6%82%E4%BD%95%E9%99%8D%E4%BD%8E%E7%94%A8%E6%88%B7%E8%BA%AB%E4%BB%BD%E9%89%B4%E6%9D%83%E7%9A%84%E6%B5%81%E9%87%8F%E5%8E%8B%E5%8A%9B/</guid>
      <description>答：用 JWT
TODO 后面再找一个 JWT 的教程吧</description>
    </item>
    
    <item>
      <title>缓存一致：读多写少时，如何解决数据更新缓存不同步</title>
      <link>https://dabao-zhao.github.io/posts/%E7%BC%93%E5%AD%98%E4%B8%80%E8%87%B4%E8%AF%BB%E5%A4%9A%E5%86%99%E5%B0%91%E6%97%B6%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3%E6%95%B0%E6%8D%AE%E6%9B%B4%E6%96%B0%E7%BC%93%E5%AD%98%E4%B8%8D%E5%90%8C%E6%AD%A5/</link>
      <pubDate>Tue, 08 Aug 2023 15:22:18 +0800</pubDate>
      
      <guid>https://dabao-zhao.github.io/posts/%E7%BC%93%E5%AD%98%E4%B8%80%E8%87%B4%E8%AF%BB%E5%A4%9A%E5%86%99%E5%B0%91%E6%97%B6%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3%E6%95%B0%E6%8D%AE%E6%9B%B4%E6%96%B0%E7%BC%93%E5%AD%98%E4%B8%8D%E5%90%8C%E6%AD%A5/</guid>
      <description>主要讲临时缓存和长期缓存，还有如何保障缓存数据的一致性
临时缓存和长期缓存 这里的临时缓存是指 TTL 比较短的缓存，长期缓存指 TTL 比较长的缓存而不是常驻的缓存
缓存更新办法 一般情况下简单数据可以在更新的时候清理缓存，等下次读取时刷新缓存，防止并发修改导致临时数据进入缓存。
复杂数据的更新可以使用 Maxwell 和 Canal 对 MySQL 的更新进行监控，这样变更信息会推送到 Kafka，然后脚本就可以进行消费去更新缓存
还介绍了版本号更新缓存和脚本遍历更新缓存，个人认为用处不大
缓存穿透问题 文里这块长期缓存和缓存穿透放一块了，其实容易让人认为长期缓存解决了缓存穿透的问题，实际上两者的关系不大。
百度百科对缓存穿透的解释是：缓存穿透是指查询一个一定不存在的数据，由于缓存是不命中时需要从数据库查询，查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到数据库去查询，进而给数据库带来压力。
临时缓存 + 长期热缓存的实现 // 尝试从缓存中直接获取用户信息 userinfo, err := Redis.Get(&amp;#34;user_info_9527&amp;#34;) if err != nil { return nil, err } //缓存命中找到，直接返回用户信息 if userinfo != nil { return userinfo, nil } //set 检测当前是否是热数据 //之所以没有使用Bloom Filter是因为有概率碰撞不准 //如果key数量超过千个，建议还是用Bloom Filter //这个判断也可以放在业务逻辑代码中，用配置同步做 isHotKey, err := Redis.SISMEMBER(&amp;#34;hot_key&amp;#34;, &amp;#34;user_info_9527&amp;#34;) if err != nil { return nil, err } //如果是热key if isHotKey { //没有找到就认为数据不存在 //可能是被删除了 return &amp;#34;&amp;#34;, nil } //没有命中缓存，并且没被标注是热点，被认为是临时缓存，那么从数据库中获取 //设置更新锁set user_info_9527_lock nx ex 5 //防止多个线程同时并发查询数据库导致数据库压力过大 lock, err := Redis.</description>
    </item>
    
    <item>
      <title>结构梳理：大并发下，你的数据库表可能成为性能隐患</title>
      <link>https://dabao-zhao.github.io/posts/%E7%BB%93%E6%9E%84%E6%A2%B3%E7%90%86%E5%A4%A7%E5%B9%B6%E5%8F%91%E4%B8%8B%E4%BD%A0%E7%9A%84%E6%95%B0%E6%8D%AE%E5%BA%93%E8%A1%A8%E5%8F%AF%E8%83%BD%E6%88%90%E4%B8%BA%E6%80%A7%E8%83%BD%E9%9A%90%E6%82%A3/</link>
      <pubDate>Tue, 08 Aug 2023 14:12:36 +0800</pubDate>
      
      <guid>https://dabao-zhao.github.io/posts/%E7%BB%93%E6%9E%84%E6%A2%B3%E7%90%86%E5%A4%A7%E5%B9%B6%E5%8F%91%E4%B8%8B%E4%BD%A0%E7%9A%84%E6%95%B0%E6%8D%AE%E5%BA%93%E8%A1%A8%E5%8F%AF%E8%83%BD%E6%88%90%E4%B8%BA%E6%80%A7%E8%83%BD%E9%9A%90%E6%82%A3/</guid>
      <description>主要以用户中心为例，讲解如何对读多写少的系统进行高并发优化。
将数据分为了四种类型：数据实体表，辅助查询表，实体关系表，历史数据表。然后根据不同类型讲述了不同的缓存策略。
数据实体表 每行数据代表一个实体，会存在一个唯一 ID。 需要根据业务需要对表进行精简，只保留所需字段，其他字段可以纵向拆分到辅助查询表。 数据小了之后，能减少 B+Tree 的层次，查询和传输也会更快。 对于这个表来说，一般会使用 前缀_ID 作为 key 进行缓存。对于一些组合条件或者对数据会做计算的一般会采用定期更新缓存的办法或者单独分出一个从库。
辅助查询表 目的是拆分出使用频率不高的字段。这里主要是提醒要定期对数据进行整理核对来保障数据的同步和完整。
实体关系表 三种关系：1:n、n:1、m:n
尽量减少 m:n 出现的可能性，如果出现要额外用一个关系表来维护关联关系。关系表在高并发系统中一般会降低一致性 要求来满足高并发的情况。主要可能会出现多级依赖。
历史数据表 一般不会去做缓存，数据量大而且增长量也大
判断是否适合缓存的核心思路 能够通过 ID 快速匹配的实体，以及通过关系快速查询的数据，适合放在长期缓存当中 通过组合条件筛选统计的数据，也可以放到临时缓存，但是更新有延迟 数据增长量大或者跟设计初衷不一样的表数据，这种不适合、也不建议去做做缓存 总结 核心就是要对数据进行归类，然后再根据归类做对应的处理</description>
    </item>
    
  </channel>
</rss>
