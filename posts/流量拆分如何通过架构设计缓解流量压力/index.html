<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="Hugo 0.116.1">

  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="author" content="赵大宝" />
  <meta property="og:url" content="https://dabao-zhao.github.io/posts/%E6%B5%81%E9%87%8F%E6%8B%86%E5%88%86%E5%A6%82%E4%BD%95%E9%80%9A%E8%BF%87%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E7%BC%93%E8%A7%A3%E6%B5%81%E9%87%8F%E5%8E%8B%E5%8A%9B/" />
  <link rel="canonical" href="https://dabao-zhao.github.io/posts/%E6%B5%81%E9%87%8F%E6%8B%86%E5%88%86%E5%A6%82%E4%BD%95%E9%80%9A%E8%BF%87%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E7%BC%93%E8%A7%A3%E6%B5%81%E9%87%8F%E5%8E%8B%E5%8A%9B/" /><link rel="apple-touch-icon" href="images/favicon.ico" />
  <link rel="icon" href="images/favicon.ico" />
  <link rel="shortcut" href="images/favicon.ico" /><link rel="alternate" type="application/atom+xml" href="https://dabao-zhao.github.ioindex.xml" title="赵大宝的博客">

  <script type="application/ld+json">
  {
      "@context" : "http://schema.org",
      "@type" : "BlogPosting",
      "mainEntityOfPage": {
           "@type": "WebPage",
           "@id": "https:\/\/dabao-zhao.github.io"
      },
      "articleSection" : "posts",
      "name" : "流量拆分：如何通过架构设计缓解流量压力",
      "headline" : "流量拆分：如何通过架构设计缓解流量压力",
      "description" : "可预估用户量的服务 可以通过压测测出单台服务器的服务在线人数，以此精确地预估带宽和服务器资源，算出一个集群（集群里包括若干服务器）需要多少资源、可以承担多少人在线进行互动，再通过调 度服务分配资源，将新来的用户分配到空闲的服务集群。\n不可预估用户量的服务 聊天 主打一个信息合并，在点赞或大量用户输入同样内容的刷屏情境下，我们可以通过大数据实时计算分析用户的输入，并压缩整理大量重复的内容，过滤掉一些无用信息。 答题 可以将数据静态化，并通过 CDN 阻挡这个流量，同时为了避免出现瞬时的高峰，推荐客户端拉取时加入随机延迟几秒，再发送请求。如果请求失败后，可以通过退火算法来设置重试时间。\n还可以将题目提前推送到客户端，减少拉取压力；同时为了让用户接收题目时间相对一致，可以在发送动作生效后 5 秒再弹出题目。\n非抢答类型的题目，用户回答完题目后，可以先在客户端本地先做预判卷，把正确答案和解析展示给用户，然后在直播期间异步缓慢地提交用户答题结果到服务端。\n点赞 客户端 客户端无需实时提交用户的所有交互，可以合并这些操作为一条消息再推送到服务端。\n服务端 通过第一层写缓存本地的实时汇总来缓解大量用户的请求，将更新数据周期性地汇总后，提交到二级写缓存。之后，二级汇总所在分片的所有上层服务数值后，最终汇 总同步给核心缓存服务。接着，通过核心缓存把最终结果汇总累加起来。最后通过主从复制到多个子查询节点服务，供用户查询汇总结果。\n适合一致性要求不高的计数器。\n打赏 \u0026amp; 购物 可以按用户 id 做 hash 拆分，通过网关将不同用户 uid 取模后，根据范围分配到不同分片服务上，然后分片内的服务对类似的请求进行内存实时计算更新。\n但 hash 分配容易出现个别热点，可以使用一致性 hash 算法，支持对局部的区域进行扩容，但也会因为算法不通用，无法人为控制，使用起来很麻烦，需要开发配套工具。\n树形热迁移切片法 比如我们将全量数据拆分成 256 份，一份代表一个桶，16 个服务器每个分 16 个桶，当我们个别服务器压力过大的时候，可以给这个服务器增加两个订阅服务器去做主从同步， 迁移这个服务器的 16 个桶的数据。待同步迁移成功后，将这个服务器的请求流量拆分转发到两个 8 桶服务器，分别请求这两个订阅服务器继续对外服务，原服务器摘除回收即可。\n服务切换成功后，由于是全量迁移，这两个服务同时同步了不属于自己的 8 个桶数据，这时新服务器遍历自己存储的数据，删除掉不属于自己的数据即可。当然也可以在同步 16 桶服务的 数据时，过滤掉这些数据，这个方法适用于 Redis、MySQL 等所有有状态分片数据服务。\n难点在于请求的客户端不直接请求分片，而是通过代理服务去请求数据服务，只有通过代理服务才能够动态更新调度流量，实现平滑无损地转发流量。\n如何让客户端知道请求哪个分片才能找到数据呢？\n客户端通过算法找到分片，比如：用户 hash(uid) % 100 = 桶 id，在配置中通过桶 id 找到对应分片。 数据服务端收到请求后，将请求转发到有数据的分片。比如客户端请求 A 分片，再根据数据算法对应的分片配置找到数据在 B 分片，这时 A 分片会转发这个请求到 B，待 B 处理后返回给客户端数据。 基础建设 分布式服务：分布式队列、分布式实时计算、分布式存储。",
      "inLanguage" : "en-US",
      "author" : "赵大宝",
      "creator" : "赵大宝",
      "publisher": "赵大宝",
      "accountablePerson" : "赵大宝",
      "copyrightHolder" : "赵大宝",
      "copyrightYear" : "2023",
      "datePublished": "2023-08-18 09:54:16 \u002b0800 CST",
      "dateModified" : "2023-08-18 09:54:16 \u002b0800 CST",
      "url" : "https:\/\/dabao-zhao.github.io\/posts\/%E6%B5%81%E9%87%8F%E6%8B%86%E5%88%86%E5%A6%82%E4%BD%95%E9%80%9A%E8%BF%87%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E7%BC%93%E8%A7%A3%E6%B5%81%E9%87%8F%E5%8E%8B%E5%8A%9B\/",
      "keywords" : [ "高并发系统实战课", ]
  }
</script>
<title>流量拆分：如何通过架构设计缓解流量压力</title>
  <meta property="og:title" content="流量拆分：如何通过架构设计缓解流量压力" />
  <meta property="og:type" content="article" />
  <meta property="og:description" content="可预估用户量的服务 可以通过压测测出单台服务器的服务在线人数，以此精确地预估带宽和服务器资源，算出一个集群（集群里包括若干服务器）需要多少资源、可以承担多少人在线进行互动，再通过调 度服务分配资源，将新来的用户分配到空闲的服务集群。
不可预估用户量的服务 聊天 主打一个信息合并，在点赞或大量用户输入同样内容的刷屏情境下，我们可以通过大数据实时计算分析用户的输入，并压缩整理大量重复的内容，过滤掉一些无用信息。 答题 可以将数据静态化，并通过 CDN 阻挡这个流量，同时为了避免出现瞬时的高峰，推荐客户端拉取时加入随机延迟几秒，再发送请求。如果请求失败后，可以通过退火算法来设置重试时间。
还可以将题目提前推送到客户端，减少拉取压力；同时为了让用户接收题目时间相对一致，可以在发送动作生效后 5 秒再弹出题目。
非抢答类型的题目，用户回答完题目后，可以先在客户端本地先做预判卷，把正确答案和解析展示给用户，然后在直播期间异步缓慢地提交用户答题结果到服务端。
点赞 客户端 客户端无需实时提交用户的所有交互，可以合并这些操作为一条消息再推送到服务端。
服务端 通过第一层写缓存本地的实时汇总来缓解大量用户的请求，将更新数据周期性地汇总后，提交到二级写缓存。之后，二级汇总所在分片的所有上层服务数值后，最终汇 总同步给核心缓存服务。接着，通过核心缓存把最终结果汇总累加起来。最后通过主从复制到多个子查询节点服务，供用户查询汇总结果。
适合一致性要求不高的计数器。
打赏 &amp;amp; 购物 可以按用户 id 做 hash 拆分，通过网关将不同用户 uid 取模后，根据范围分配到不同分片服务上，然后分片内的服务对类似的请求进行内存实时计算更新。
但 hash 分配容易出现个别热点，可以使用一致性 hash 算法，支持对局部的区域进行扩容，但也会因为算法不通用，无法人为控制，使用起来很麻烦，需要开发配套工具。
树形热迁移切片法 比如我们将全量数据拆分成 256 份，一份代表一个桶，16 个服务器每个分 16 个桶，当我们个别服务器压力过大的时候，可以给这个服务器增加两个订阅服务器去做主从同步， 迁移这个服务器的 16 个桶的数据。待同步迁移成功后，将这个服务器的请求流量拆分转发到两个 8 桶服务器，分别请求这两个订阅服务器继续对外服务，原服务器摘除回收即可。
服务切换成功后，由于是全量迁移，这两个服务同时同步了不属于自己的 8 个桶数据，这时新服务器遍历自己存储的数据，删除掉不属于自己的数据即可。当然也可以在同步 16 桶服务的 数据时，过滤掉这些数据，这个方法适用于 Redis、MySQL 等所有有状态分片数据服务。
难点在于请求的客户端不直接请求分片，而是通过代理服务去请求数据服务，只有通过代理服务才能够动态更新调度流量，实现平滑无损地转发流量。
如何让客户端知道请求哪个分片才能找到数据呢？
客户端通过算法找到分片，比如：用户 hash(uid) % 100 = 桶 id，在配置中通过桶 id 找到对应分片。 数据服务端收到请求后，将请求转发到有数据的分片。比如客户端请求 A 分片，再根据数据算法对应的分片配置找到数据在 B 分片，这时 A 分片会转发这个请求到 B，待 B 处理后返回给客户端数据。 基础建设 分布式服务：分布式队列、分布式实时计算、分布式存储。" />
  <meta name="description" content="可预估用户量的服务 可以通过压测测出单台服务器的服务在线人数，以此精确地预估带宽和服务器资源，算出一个集群（集群里包括若干服务器）需要多少资源、可以承担多少人在线进行互动，再通过调 度服务分配资源，将新来的用户分配到空闲的服务集群。
不可预估用户量的服务 聊天 主打一个信息合并，在点赞或大量用户输入同样内容的刷屏情境下，我们可以通过大数据实时计算分析用户的输入，并压缩整理大量重复的内容，过滤掉一些无用信息。 答题 可以将数据静态化，并通过 CDN 阻挡这个流量，同时为了避免出现瞬时的高峰，推荐客户端拉取时加入随机延迟几秒，再发送请求。如果请求失败后，可以通过退火算法来设置重试时间。
还可以将题目提前推送到客户端，减少拉取压力；同时为了让用户接收题目时间相对一致，可以在发送动作生效后 5 秒再弹出题目。
非抢答类型的题目，用户回答完题目后，可以先在客户端本地先做预判卷，把正确答案和解析展示给用户，然后在直播期间异步缓慢地提交用户答题结果到服务端。
点赞 客户端 客户端无需实时提交用户的所有交互，可以合并这些操作为一条消息再推送到服务端。
服务端 通过第一层写缓存本地的实时汇总来缓解大量用户的请求，将更新数据周期性地汇总后，提交到二级写缓存。之后，二级汇总所在分片的所有上层服务数值后，最终汇 总同步给核心缓存服务。接着，通过核心缓存把最终结果汇总累加起来。最后通过主从复制到多个子查询节点服务，供用户查询汇总结果。
适合一致性要求不高的计数器。
打赏 &amp;amp; 购物 可以按用户 id 做 hash 拆分，通过网关将不同用户 uid 取模后，根据范围分配到不同分片服务上，然后分片内的服务对类似的请求进行内存实时计算更新。
但 hash 分配容易出现个别热点，可以使用一致性 hash 算法，支持对局部的区域进行扩容，但也会因为算法不通用，无法人为控制，使用起来很麻烦，需要开发配套工具。
树形热迁移切片法 比如我们将全量数据拆分成 256 份，一份代表一个桶，16 个服务器每个分 16 个桶，当我们个别服务器压力过大的时候，可以给这个服务器增加两个订阅服务器去做主从同步， 迁移这个服务器的 16 个桶的数据。待同步迁移成功后，将这个服务器的请求流量拆分转发到两个 8 桶服务器，分别请求这两个订阅服务器继续对外服务，原服务器摘除回收即可。
服务切换成功后，由于是全量迁移，这两个服务同时同步了不属于自己的 8 个桶数据，这时新服务器遍历自己存储的数据，删除掉不属于自己的数据即可。当然也可以在同步 16 桶服务的 数据时，过滤掉这些数据，这个方法适用于 Redis、MySQL 等所有有状态分片数据服务。
难点在于请求的客户端不直接请求分片，而是通过代理服务去请求数据服务，只有通过代理服务才能够动态更新调度流量，实现平滑无损地转发流量。
如何让客户端知道请求哪个分片才能找到数据呢？
客户端通过算法找到分片，比如：用户 hash(uid) % 100 = 桶 id，在配置中通过桶 id 找到对应分片。 数据服务端收到请求后，将请求转发到有数据的分片。比如客户端请求 A 分片，再根据数据算法对应的分片配置找到数据在 B 分片，这时 A 分片会转发这个请求到 B，待 B 处理后返回给客户端数据。 基础建设 分布式服务：分布式队列、分布式实时计算、分布式存储。" />
  <meta property="og:locale" content="zh-cn" /><meta property="og:image" content="images/favicon.ico" />
  

  
    <style>body{font-family:bree serif,sans-serif;-webkit-font-smoothing:antialiased;margin:0 20px}article{max-width:800px;margin-left:auto;margin-right:auto}a{color:#000;text-decoration:none}a:hover{font-weight:600;text-decoration:underline}.post-ads{margin:50px 0}.markdown-body{font-size:18px;max-width:100%}.markdown-body a{text-decoration:underline;text-decoration-color:#000}.markdown-body blockquote{margin:0;padding:0 1em;color:#57606a;border-left:.25em solid #d0d7de}.markdown-body pre{padding:16px;overflow:auto;border-radius:10px}.markdown-body code{padding:.2em .4em;font-size:85%;background-color:#f6f8fa;border-radius:6px}.markdown-body pre>code{padding:0;font-size:100%;background-color:inherit;border:0}.Chinese .markdown-body{line-height:200%}.site-date-catalog{font-size:2rem}.header-title{font-size:2rem;font-weight:700;margin-top:32px;font-family:bungee shade,sans-serif}.header-title a{text-decoration:none}.header-subtitle{color:#666}.header-items{margin:10px 0}.header-item{margin:0 5px}.header-line{width:100%;border-width:2px;border-color:#482936;border-style:solid none none none}.lang-switch{font-weight:600}#posts-list{min-height:600px}.posts-line{font-size:1.2rem;margin:12px 0}.posts-categories{font-size:.8rem;margin:auto;text-align:center}.posts-category{padding:3px 0;border:#000 2px solid;border-radius:5px}.site-footer{margin-top:50px}.site-footer-item{margin-right:12px}.post-content img{max-width:100%;display:block;margin-right:auto;margin-top:12px}.post-header{margin-bottom:50px}.post-title{font-size:2rem;font-weight:600}.post-tags{display:inline;font-weight:600;padding:2px 5px;margin-right:6px;border:#000 2px solid;border-radius:5px}.post-date{font-weight:800;font-style:italic}.post-author{float:right;font-weight:600}.page-content{min-height:60%}.post-content{margin-bottom:50px}.post-content p{hyphens:auto;line-height:1.8;text-justify:ideographic;margin-bottom:1em}.related-content{border-width:3px;border-style:solid;border-color:#000;padding:0 10px;margin-bottom:50px;margin-top:100px}.related-content li{margin:5px 0}.taxonomy-term{font-size:3rem}.gallery-img{text-align:center}.gallery-img span{text-align:center}.gallery-img-desc{font-size:.8em;font-weight:800}#disqus_thread{position:relative}#disqus_thread:after{content:"";display:block;height:55px;width:100%;position:absolute;bottom:0;background:#fff}@media screen and (max-width:600px){.header-title,.header-subtitle,.header-items{text-align:center}.posts-line{font-size:16px}.markdown-body{font-size:16px}.post-title{font-size:2rem}.post-content p{letter-spacing:.05em}}@media screen and (max-width:48em){.posts-category{display:none}}</style>
  
  
    <style>.container,.container-fluid{margin-right:auto;margin-left:auto}.container-fluid{padding-right:2rem;padding-left:2rem}.row{box-sizing:border-box;display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-flex:0;-ms-flex:0 1 auto;flex:initial;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;-ms-flex-wrap:wrap;flex-wrap:wrap;margin-right:-.5rem;margin-left:-.5rem}.row.reverse{-webkit-box-orient:horizontal;-webkit-box-direction:reverse;-ms-flex-direction:row-reverse;flex-direction:row-reverse}.col.reverse{-webkit-box-orient:vertical;-webkit-box-direction:reverse;-ms-flex-direction:column-reverse;flex-direction:column-reverse}.col-xs,.col-xs-1,.col-xs-10,.col-xs-11,.col-xs-12,.col-xs-2,.col-xs-3,.col-xs-4,.col-xs-5,.col-xs-6,.col-xs-7,.col-xs-8,.col-xs-9,.col-xs-offset-0,.col-xs-offset-1,.col-xs-offset-10,.col-xs-offset-11,.col-xs-offset-12,.col-xs-offset-2,.col-xs-offset-3,.col-xs-offset-4,.col-xs-offset-5,.col-xs-offset-6,.col-xs-offset-7,.col-xs-offset-8,.col-xs-offset-9{box-sizing:border-box;-webkit-box-flex:0;-ms-flex:0 0 auto;flex:none;padding-right:.5rem;padding-left:.5rem}.col-xs{-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1;-ms-flex-preferred-size:0;flex-basis:0;max-width:100%}.col-xs-1{-ms-flex-preferred-size:8.33333333%;flex-basis:8.33333333%;max-width:8.33333333%}.col-xs-2{-ms-flex-preferred-size:16.66666667%;flex-basis:16.66666667%;max-width:16.66666667%}.col-xs-3{-ms-flex-preferred-size:25%;flex-basis:25%;max-width:25%}.col-xs-4{-ms-flex-preferred-size:33.33333333%;flex-basis:33.33333333%;max-width:33.33333333%}.col-xs-5{-ms-flex-preferred-size:41.66666667%;flex-basis:41.66666667%;max-width:41.66666667%}.col-xs-6{-ms-flex-preferred-size:50%;flex-basis:50%;max-width:50%}.col-xs-7{-ms-flex-preferred-size:58.33333333%;flex-basis:58.33333333%;max-width:58.33333333%}.col-xs-8{-ms-flex-preferred-size:66.66666667%;flex-basis:66.66666667%;max-width:66.66666667%}.col-xs-9{-ms-flex-preferred-size:75%;flex-basis:75%;max-width:75%}.col-xs-10{-ms-flex-preferred-size:83.33333333%;flex-basis:83.33333333%;max-width:83.33333333%}.col-xs-11{-ms-flex-preferred-size:91.66666667%;flex-basis:91.66666667%;max-width:91.66666667%}.col-xs-12{-ms-flex-preferred-size:100%;flex-basis:100%;max-width:100%}.col-xs-offset-0{margin-left:0}.col-xs-offset-1{margin-left:8.33333333%}.col-xs-offset-2{margin-left:16.66666667%}.col-xs-offset-3{margin-left:25%}.col-xs-offset-4{margin-left:33.33333333%}.col-xs-offset-5{margin-left:41.66666667%}.col-xs-offset-6{margin-left:50%}.col-xs-offset-7{margin-left:58.33333333%}.col-xs-offset-8{margin-left:66.66666667%}.col-xs-offset-9{margin-left:75%}.col-xs-offset-10{margin-left:83.33333333%}.col-xs-offset-11{margin-left:91.66666667%}.start-xs{-webkit-box-pack:start;-ms-flex-pack:start;justify-content:flex-start;text-align:start}.center-xs{-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;text-align:center}.end-xs{-webkit-box-pack:end;-ms-flex-pack:end;justify-content:flex-end;text-align:end}.top-xs{-webkit-box-align:start;-ms-flex-align:start;align-items:flex-start}.middle-xs{-webkit-box-align:center;-ms-flex-align:center;align-items:center}.bottom-xs{-webkit-box-align:end;-ms-flex-align:end;align-items:flex-end}.around-xs{-ms-flex-pack:distribute;justify-content:space-around}.between-xs{-webkit-box-pack:justify;-ms-flex-pack:justify;justify-content:space-between}.first-xs{-webkit-box-ordinal-group:0;-ms-flex-order:-1;order:-1}.last-xs{-webkit-box-ordinal-group:2;-ms-flex-order:1;order:1}@media only screen and (min-width:48em){.container{width:49rem}.col-sm,.col-sm-1,.col-sm-10,.col-sm-11,.col-sm-12,.col-sm-2,.col-sm-3,.col-sm-4,.col-sm-5,.col-sm-6,.col-sm-7,.col-sm-8,.col-sm-9,.col-sm-offset-0,.col-sm-offset-1,.col-sm-offset-10,.col-sm-offset-11,.col-sm-offset-12,.col-sm-offset-2,.col-sm-offset-3,.col-sm-offset-4,.col-sm-offset-5,.col-sm-offset-6,.col-sm-offset-7,.col-sm-offset-8,.col-sm-offset-9{box-sizing:border-box;-webkit-box-flex:0;-ms-flex:0 0 auto;flex:none;padding-right:.5rem;padding-left:.5rem}.col-sm{-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1;-ms-flex-preferred-size:0;flex-basis:0;max-width:100%}.col-sm-1{-ms-flex-preferred-size:8.33333333%;flex-basis:8.33333333%;max-width:8.33333333%}.col-sm-2{-ms-flex-preferred-size:16.66666667%;flex-basis:16.66666667%;max-width:16.66666667%}.col-sm-3{-ms-flex-preferred-size:25%;flex-basis:25%;max-width:25%}.col-sm-4{-ms-flex-preferred-size:33.33333333%;flex-basis:33.33333333%;max-width:33.33333333%}.col-sm-5{-ms-flex-preferred-size:41.66666667%;flex-basis:41.66666667%;max-width:41.66666667%}.col-sm-6{-ms-flex-preferred-size:50%;flex-basis:50%;max-width:50%}.col-sm-7{-ms-flex-preferred-size:58.33333333%;flex-basis:58.33333333%;max-width:58.33333333%}.col-sm-8{-ms-flex-preferred-size:66.66666667%;flex-basis:66.66666667%;max-width:66.66666667%}.col-sm-9{-ms-flex-preferred-size:75%;flex-basis:75%;max-width:75%}.col-sm-10{-ms-flex-preferred-size:83.33333333%;flex-basis:83.33333333%;max-width:83.33333333%}.col-sm-11{-ms-flex-preferred-size:91.66666667%;flex-basis:91.66666667%;max-width:91.66666667%}.col-sm-12{-ms-flex-preferred-size:100%;flex-basis:100%;max-width:100%}.col-sm-offset-0{margin-left:0}.col-sm-offset-1{margin-left:8.33333333%}.col-sm-offset-2{margin-left:16.66666667%}.col-sm-offset-3{margin-left:25%}.col-sm-offset-4{margin-left:33.33333333%}.col-sm-offset-5{margin-left:41.66666667%}.col-sm-offset-6{margin-left:50%}.col-sm-offset-7{margin-left:58.33333333%}.col-sm-offset-8{margin-left:66.66666667%}.col-sm-offset-9{margin-left:75%}.col-sm-offset-10{margin-left:83.33333333%}.col-sm-offset-11{margin-left:91.66666667%}.start-sm{-webkit-box-pack:start;-ms-flex-pack:start;justify-content:flex-start;text-align:start}.center-sm{-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;text-align:center}.end-sm{-webkit-box-pack:end;-ms-flex-pack:end;justify-content:flex-end;text-align:end}.top-sm{-webkit-box-align:start;-ms-flex-align:start;align-items:flex-start}.middle-sm{-webkit-box-align:center;-ms-flex-align:center;align-items:center}.bottom-sm{-webkit-box-align:end;-ms-flex-align:end;align-items:flex-end}.around-sm{-ms-flex-pack:distribute;justify-content:space-around}.between-sm{-webkit-box-pack:justify;-ms-flex-pack:justify;justify-content:space-between}.first-sm{-webkit-box-ordinal-group:0;-ms-flex-order:-1;order:-1}.last-sm{-webkit-box-ordinal-group:2;-ms-flex-order:1;order:1}}@media only screen and (min-width:64em){.container{width:65rem}.col-md,.col-md-1,.col-md-10,.col-md-11,.col-md-12,.col-md-2,.col-md-3,.col-md-4,.col-md-5,.col-md-6,.col-md-7,.col-md-8,.col-md-9,.col-md-offset-0,.col-md-offset-1,.col-md-offset-10,.col-md-offset-11,.col-md-offset-12,.col-md-offset-2,.col-md-offset-3,.col-md-offset-4,.col-md-offset-5,.col-md-offset-6,.col-md-offset-7,.col-md-offset-8,.col-md-offset-9{box-sizing:border-box;-webkit-box-flex:0;-ms-flex:0 0 auto;flex:none;padding-right:.5rem;padding-left:.5rem}.col-md{-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1;-ms-flex-preferred-size:0;flex-basis:0;max-width:100%}.col-md-1{-ms-flex-preferred-size:8.33333333%;flex-basis:8.33333333%;max-width:8.33333333%}.col-md-2{-ms-flex-preferred-size:16.66666667%;flex-basis:16.66666667%;max-width:16.66666667%}.col-md-3{-ms-flex-preferred-size:25%;flex-basis:25%;max-width:25%}.col-md-4{-ms-flex-preferred-size:33.33333333%;flex-basis:33.33333333%;max-width:33.33333333%}.col-md-5{-ms-flex-preferred-size:41.66666667%;flex-basis:41.66666667%;max-width:41.66666667%}.col-md-6{-ms-flex-preferred-size:50%;flex-basis:50%;max-width:50%}.col-md-7{-ms-flex-preferred-size:58.33333333%;flex-basis:58.33333333%;max-width:58.33333333%}.col-md-8{-ms-flex-preferred-size:66.66666667%;flex-basis:66.66666667%;max-width:66.66666667%}.col-md-9{-ms-flex-preferred-size:75%;flex-basis:75%;max-width:75%}.col-md-10{-ms-flex-preferred-size:83.33333333%;flex-basis:83.33333333%;max-width:83.33333333%}.col-md-11{-ms-flex-preferred-size:91.66666667%;flex-basis:91.66666667%;max-width:91.66666667%}.col-md-12{-ms-flex-preferred-size:100%;flex-basis:100%;max-width:100%}.col-md-offset-0{margin-left:0}.col-md-offset-1{margin-left:8.33333333%}.col-md-offset-2{margin-left:16.66666667%}.col-md-offset-3{margin-left:25%}.col-md-offset-4{margin-left:33.33333333%}.col-md-offset-5{margin-left:41.66666667%}.col-md-offset-6{margin-left:50%}.col-md-offset-7{margin-left:58.33333333%}.col-md-offset-8{margin-left:66.66666667%}.col-md-offset-9{margin-left:75%}.col-md-offset-10{margin-left:83.33333333%}.col-md-offset-11{margin-left:91.66666667%}.start-md{-webkit-box-pack:start;-ms-flex-pack:start;justify-content:flex-start;text-align:start}.center-md{-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;text-align:center}.end-md{-webkit-box-pack:end;-ms-flex-pack:end;justify-content:flex-end;text-align:end}.top-md{-webkit-box-align:start;-ms-flex-align:start;align-items:flex-start}.middle-md{-webkit-box-align:center;-ms-flex-align:center;align-items:center}.bottom-md{-webkit-box-align:end;-ms-flex-align:end;align-items:flex-end}.around-md{-ms-flex-pack:distribute;justify-content:space-around}.between-md{-webkit-box-pack:justify;-ms-flex-pack:justify;justify-content:space-between}.first-md{-webkit-box-ordinal-group:0;-ms-flex-order:-1;order:-1}.last-md{-webkit-box-ordinal-group:2;-ms-flex-order:1;order:1}}@media only screen and (min-width:75em){.container{width:76rem}.col-lg,.col-lg-1,.col-lg-10,.col-lg-11,.col-lg-12,.col-lg-2,.col-lg-3,.col-lg-4,.col-lg-5,.col-lg-6,.col-lg-7,.col-lg-8,.col-lg-9,.col-lg-offset-0,.col-lg-offset-1,.col-lg-offset-10,.col-lg-offset-11,.col-lg-offset-12,.col-lg-offset-2,.col-lg-offset-3,.col-lg-offset-4,.col-lg-offset-5,.col-lg-offset-6,.col-lg-offset-7,.col-lg-offset-8,.col-lg-offset-9{box-sizing:border-box;-webkit-box-flex:0;-ms-flex:0 0 auto;flex:none;padding-right:.5rem;padding-left:.5rem}.col-lg{-webkit-box-flex:1;-ms-flex-positive:1;flex-grow:1;-ms-flex-preferred-size:0;flex-basis:0;max-width:100%}.col-lg-1{-ms-flex-preferred-size:8.33333333%;flex-basis:8.33333333%;max-width:8.33333333%}.col-lg-2{-ms-flex-preferred-size:16.66666667%;flex-basis:16.66666667%;max-width:16.66666667%}.col-lg-3{-ms-flex-preferred-size:25%;flex-basis:25%;max-width:25%}.col-lg-4{-ms-flex-preferred-size:33.33333333%;flex-basis:33.33333333%;max-width:33.33333333%}.col-lg-5{-ms-flex-preferred-size:41.66666667%;flex-basis:41.66666667%;max-width:41.66666667%}.col-lg-6{-ms-flex-preferred-size:50%;flex-basis:50%;max-width:50%}.col-lg-7{-ms-flex-preferred-size:58.33333333%;flex-basis:58.33333333%;max-width:58.33333333%}.col-lg-8{-ms-flex-preferred-size:66.66666667%;flex-basis:66.66666667%;max-width:66.66666667%}.col-lg-9{-ms-flex-preferred-size:75%;flex-basis:75%;max-width:75%}.col-lg-10{-ms-flex-preferred-size:83.33333333%;flex-basis:83.33333333%;max-width:83.33333333%}.col-lg-11{-ms-flex-preferred-size:91.66666667%;flex-basis:91.66666667%;max-width:91.66666667%}.col-lg-12{-ms-flex-preferred-size:100%;flex-basis:100%;max-width:100%}.col-lg-offset-0{margin-left:0}.col-lg-offset-1{margin-left:8.33333333%}.col-lg-offset-2{margin-left:16.66666667%}.col-lg-offset-3{margin-left:25%}.col-lg-offset-4{margin-left:33.33333333%}.col-lg-offset-5{margin-left:41.66666667%}.col-lg-offset-6{margin-left:50%}.col-lg-offset-7{margin-left:58.33333333%}.col-lg-offset-8{margin-left:66.66666667%}.col-lg-offset-9{margin-left:75%}.col-lg-offset-10{margin-left:83.33333333%}.col-lg-offset-11{margin-left:91.66666667%}.start-lg{-webkit-box-pack:start;-ms-flex-pack:start;justify-content:flex-start;text-align:start}.center-lg{-webkit-box-pack:center;-ms-flex-pack:center;justify-content:center;text-align:center}.end-lg{-webkit-box-pack:end;-ms-flex-pack:end;justify-content:flex-end;text-align:end}.top-lg{-webkit-box-align:start;-ms-flex-align:start;align-items:flex-start}.middle-lg{-webkit-box-align:center;-ms-flex-align:center;align-items:center}.bottom-lg{-webkit-box-align:end;-ms-flex-align:end;align-items:flex-end}.around-lg{-ms-flex-pack:distribute;justify-content:space-around}.between-lg{-webkit-box-pack:justify;-ms-flex-pack:justify;justify-content:space-between}.first-lg{-webkit-box-ordinal-group:0;-ms-flex-order:-1;order:-1}.last-lg{-webkit-box-ordinal-group:2;-ms-flex-order:1;order:1}}</style>
  

  

  <link href="/index.xml" rel="alternate" type="application/rss+xml"
    title="赵大宝的博客">
  
  <link rel="preconnect" href="https://fonts.gstatic.com">
  <link href="https://fonts.googleapis.com/css?family=Bree+Serif|Bungee+Shade" rel="stylesheet">
  
  

  
  
</head>


<body>
  <article class="post " id="article">
    <div class="row">
      <div class="col-xs-12">
        <div class="site-header">
          
<header>
  <div class="header-title">
    <a href="/"
      >赵大宝</a
    >
  </div>
  <div class="header-subtitle">以无用之事，修自在之心</div>
</header>
<div class="row end-md center-xs header-items">
  
  <div class="header-item">
    <a href="/index.xml" target="_blank">RSS</a>
  </div>
  
</div>
<div class="row end-xs">
   
</div>
<div class="header-line"></div>

        </div>
        <header class="post-header">
          <h1 class="post-title">流量拆分：如何通过架构设计缓解流量压力</h1>
          
          <div class="row post-desc">
            <div class="col-xs-6">
              
              <time class="post-date" datetime="2023-08-18 09:54:16 CST">
                18 Aug 2023
              </time>
              
            </div>
            <div class="col-xs-6">
              
              <div class="post-author">
                <a target="_blank" href="https://dabao-zhao.github.io">@赵大宝</a>
              </div>
              
            </div>
          </div>
          
        </header>

        <div class="post-content markdown-body">
          
          <h3 id="可预估用户量的服务">可预估用户量的服务</h3>
<p>可以通过压测测出单台服务器的服务在线人数，以此精确地预估带宽和服务器资源，算出一个集群（集群里包括若干服务器）需要多少资源、可以承担多少人在线进行互动，再通过调
度服务分配资源，将新来的用户分配到空闲的服务集群。</p>
<p><img src="/images/architecture/architecture.png" alt="architecture"></p>
<h3 id="不可预估用户量的服务">不可预估用户量的服务</h3>
<h4 id="聊天">聊天</h4>
<p>主打一个信息合并，在点赞或大量用户输入同样内容的刷屏情境下，我们可以通过大数据实时计算分析用户的输入，并压缩整理大量重复的内容，过滤掉一些无用信息。
<img src="/images/architecture/architecture2.png" alt="architecture"></p>
<h4 id="答题">答题</h4>
<p>可以将数据静态化，并通过 CDN 阻挡这个流量，同时为了避免出现瞬时的高峰，推荐客户端拉取时加入随机延迟几秒，再发送请求。如果请求失败后，可以通过退火算法来设置重试时间。</p>
<p>还可以将题目提前推送到客户端，减少拉取压力；同时为了让用户接收题目时间相对一致，可以在发送动作生效后 5 秒再弹出题目。</p>
<p>非抢答类型的题目，用户回答完题目后，可以先在客户端本地先做预判卷，把正确答案和解析展示给用户，然后在直播期间异步缓慢地提交用户答题结果到服务端。</p>
<h4 id="点赞">点赞</h4>
<h5 id="客户端">客户端</h5>
<p>客户端无需实时提交用户的所有交互，可以合并这些操作为一条消息再推送到服务端。</p>
<h5 id="服务端">服务端</h5>
<p><img src="/images/architecture/architecture3.png" alt="architecture"></p>
<p>通过第一层写缓存本地的实时汇总来缓解大量用户的请求，将更新数据周期性地汇总后，提交到二级写缓存。之后，二级汇总所在分片的所有上层服务数值后，最终汇
总同步给核心缓存服务。接着，通过核心缓存把最终结果汇总累加起来。最后通过主从复制到多个子查询节点服务，供用户查询汇总结果。</p>
<p>适合一致性要求不高的计数器。</p>
<h4 id="打赏--购物">打赏 &amp; 购物</h4>
<p><img src="/images/architecture/architecture4.png" alt="architecture"></p>
<p>可以按用户 id 做 hash 拆分，通过网关将不同用户 uid 取模后，根据范围分配到不同分片服务上，然后分片内的服务对类似的请求进行内存实时计算更新。<br>
但 hash 分配容易出现个别热点，可以使用一致性 hash 算法，支持对局部的区域进行扩容，但也会因为算法不通用，无法人为控制，使用起来很麻烦，需要开发配套工具。</p>
<h5 id="树形热迁移切片法">树形热迁移切片法</h5>
<p>比如我们将全量数据拆分成 256 份，一份代表一个桶，16 个服务器每个分 16 个桶，当我们个别服务器压力过大的时候，可以给这个服务器增加两个订阅服务器去做主从同步，
迁移这个服务器的 16 个桶的数据。待同步迁移成功后，将这个服务器的请求流量拆分转发到两个 8 桶服务器，分别请求这两个订阅服务器继续对外服务，原服务器摘除回收即可。</p>
<p>服务切换成功后，由于是全量迁移，这两个服务同时同步了不属于自己的 8 个桶数据，这时新服务器遍历自己存储的数据，删除掉不属于自己的数据即可。当然也可以在同步 16 桶服务的
数据时，过滤掉这些数据，这个方法适用于 Redis、MySQL 等所有有状态分片数据服务。</p>
<p>难点在于请求的客户端不直接请求分片，而是通过代理服务去请求数据服务，只有通过代理服务才能够动态更新调度流量，实现平滑无损地转发流量。</p>
<p>如何让客户端知道请求哪个分片才能找到数据呢？</p>
<ul>
<li>客户端通过算法找到分片，比如：用户 hash(uid) % 100 = 桶 id，在配置中通过桶 id 找到对应分片。</li>
<li>数据服务端收到请求后，将请求转发到有数据的分片。比如客户端请求 A 分片，再根据数据算法对应的分片配置找到数据在 B 分片，这时 A 分片会转发这个请求到 B，待 B 处理后返回给客户端数据。</li>
</ul>
<h3 id="基础建设">基础建设</h3>
<p>分布式服务：分布式队列、分布式实时计算、分布式存储。<br>
动态容器：服务器统一调度系统、自动化运维、周期压力测试、Kubernetes 动态扩容服务。<br>
调度服务：通过 HttpDNS 临时调度用户流量等服务，来实现动态的资源调配。</p>

        </div>

        <div class="row middle-xs">
          <div class="col-xs-12">
            
            <div class="post-tags">
              <a href="/tags/%E9%AB%98%E5%B9%B6%E5%8F%91%E7%B3%BB%E7%BB%9F%E5%AE%9E%E6%88%98%E8%AF%BE/">
                高并发系统实战课
              </a>
            </div>
            
          </div>
        </div>
        
          <div class="row">
            <div class="col-xs-12">
              
            </div>
          </div>

          

<div class="related-content">
  <h3>Related Posts</h3>
  <ul>
    
    <li><a href="/posts/%E4%B8%9A%E5%8A%A1%E8%84%9A%E6%9C%AC%E4%B8%BA%E4%BB%80%E4%B9%88%E8%AF%B4%E5%8F%AF%E7%BC%96%E7%A8%8B%E8%AE%A2%E9%98%85%E5%BC%8F%E7%BC%93%E5%AD%98%E6%9C%8D%E5%8A%A1%E6%9B%B4%E6%9C%89%E7%94%A8/">业务脚本：为什么说可编程订阅式缓存服务更有用</a></li>
    
    <li><a href="/posts/%E6%9C%AC%E5%9C%B0%E7%BC%93%E5%AD%98%E7%94%A8%E6%9C%AC%E5%9C%B0%E7%BC%93%E5%AD%98%E5%81%9A%E6%9C%8D%E5%8A%A1%E4%BC%9A%E9%81%87%E5%88%B0%E5%93%AA%E4%BA%9B%E5%9D%91/">本地缓存：用本地缓存做服务会遇到哪些坑</a></li>
    
    <li><a href="/posts/%E5%AE%9E%E8%B7%B5%E6%96%B9%E6%A1%88%E5%A6%82%E4%BD%95%E7%94%A8c&#43;&#43;%E8%87%AA%E5%AE%9E%E7%8E%B0%E9%93%BE%E8%B7%AF%E8%B7%9F%E8%B8%AA/">实践方案：如何用C&#43;&#43;自实现链路跟踪</a></li>
    
  </ul>
</div>



          
          
          <div style="height: 50px;"></div>
          
        

        <div class="site-footer">
  
  
</div>

      </div>
    </div>
  </article>

  

<script>
  
  
    
    
  
</script>

  

</body>

</html>